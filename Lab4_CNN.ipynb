{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science - Laboratorio 4\n",
    "## Redes neuronales convolucionales (CNN) \n",
    "- - -\n",
    "### Integrantes:\n",
    "- Diego Alberto Leiva 21752\n",
    "- José Pablo Orellana 21970\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: Importante tener el Token de la API en el folder `C:\\Users\\<Windows-username>\\.kaggle\\kaggle.json`\n",
    "\n",
    "Para mas detalles de otros sistemas dirigirse a: https://github.com/Kaggle/kaggle-api/tree/main/docs#api-credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle API\n",
    "import kaggle\n",
    "from kaggle.rest import ApiException\n",
    "\n",
    "# Operaciones de archivos\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Visualización\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/agungpambudi/mnist-multiple-dataset-comprehensive-analysis\n",
      "Downloading mnist-multiple-dataset-comprehensive-analysis.zip to c:\\Users\\diego\\Documents\\UVG\\8vo Semestre\\Data Science\\Lab4-DataScience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 874M/874M [00:36<00:00, 25.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXITO: Dataset descargado como 'mnist-multiple-dataset-comprehensive-analysis.zip'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Descomprimiendo archivos: 100%|██████████| 350000/350000 [02:09<00:00, 2700.00archivo/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXITO: Archivos de PolyMNIST descomprimidos en 'dataset'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Nombre del dataset y rutas\n",
    "dataset_name = 'agungpambudi/mnist-multiple-dataset-comprehensive-analysis'     # Nombre del dataset\n",
    "download_path = 'mnist-multiple-dataset-comprehensive-analysis.zip'             # Ruta de descarga\n",
    "target_dir = 'dataset'                                                            # Directorio de destino\n",
    "\n",
    "# Verificar si ya existe el directorio de destino\n",
    "if not os.path.exists(target_dir):\n",
    "    # Autenticar con la API de Kaggle\n",
    "    kaggle.api.authenticate()\n",
    "\n",
    "    try:\n",
    "        # Descargar el dataset de Kaggle si no existe\n",
    "        if not os.path.exists(download_path):\n",
    "            kaggle.api.dataset_download_files(dataset=dataset_name,\n",
    "                                              quiet=False, \n",
    "                                              unzip=False)\n",
    "            print(f\"EXITO: Dataset descargado como '{download_path}'.\\n\")\n",
    "\n",
    "    # Manejo de errores\n",
    "    except ApiException as e:\n",
    "        print(\"ERROR al llamar a KaggleApi -> datasets_download: %s\\n\" % e)\n",
    "\n",
    "    try:\n",
    "        # Descomprimir únicamente la carpeta MMNIST\n",
    "        with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "            members = [m for m in zip_ref.namelist() if m.startswith('PolyMNIST/MMNIST/')]\n",
    "            \n",
    "            # Barra de progreso para la descompresión\n",
    "            for member in tqdm(members, desc=\"Descomprimiendo archivos\", unit=\"archivo\"):\n",
    "                # Obtener el nombre del archivo relativo a MMNIST\n",
    "                filename = os.path.relpath(member, 'PolyMNIST/MMNIST/')\n",
    "                target_path = os.path.join(target_dir, filename)\n",
    "                \n",
    "                if not member.endswith('/'):\n",
    "                    # Crear el directorio de destino si no existe\n",
    "                    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                    # Extraer el archivo\n",
    "                    with zip_ref.open(member) as source, open(target_path, 'wb') as target:\n",
    "                        target.write(source.read())\n",
    "\n",
    "        # Eliminar el archivo ZIP después de la extracción\n",
    "        os.remove(download_path)\n",
    "        print(f\"\\nEXITO: Archivos de PolyMNIST descomprimidos en '{target_dir}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR al descomprimir el dataset: %s\\n\" % e)\n",
    "\n",
    "else:\n",
    "    # Si ya existe el directorio, no hacer nada\n",
    "    print(f\"{target_dir} ya existe. Se omite la descarga y la extracción.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
